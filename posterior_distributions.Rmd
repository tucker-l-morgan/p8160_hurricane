---
title: "P8160 - Hurricane Project"
author: "Tucker Morgan - tlm2152"
date: "4/26/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Given Information

The following Bayesian model was suggested.  

$$Y_{i}(t+6) =\beta_{0,i}+\beta_{1,i}Y_{i}(t) + \beta_{2,i}\Delta_{i,1}(t)+
\beta_{3,i}\Delta_{i,2}(t) +\beta_{4,i}\Delta_{i,3}(t)  + \epsilon_{i}(t)$$  

where $Y_{i}(t)$ the wind speed at time $t$ (i.e. 6 hours earlier),  $\Delta_{i,1}(t)$, $\Delta_{i,2}(t)$ and $\Delta_{i,3}(t)$ are the changes of latitude, longitude and wind speed between $t$ and $t+6$, and $\epsilon_{i,t}$ follows a  normal distributions with mean zero and variance $\sigma^2$, independent across $t$. 

In the model,  $\boldsymbol{\beta}_{i} =  (\beta_{0,i},\beta_{1,i},...,\beta_{7,i})$ are the random coefficients associated the $i$th hurricane, we assume that 

$$\boldsymbol{\beta}_{i} \sim N(\boldsymbol{\beta}, \boldsymbol{\Sigma})$$

follows a multivariate normal distributions with mean $\boldsymbol{\beta}$ and covariance matrix $\Sigma$.

We assume the following non-informative or weak prior distributions for $\sigma^2$, $\boldsymbol{\beta}$ and $\Sigma$.

$$P(\sigma^2) \propto \frac{1}{\sigma^2};\quad P(\boldsymbol{\beta})\propto 1;\quad P(\Sigma^{-1}) \propto 
|\Sigma|^{-(d+1)} \exp(-\frac{1}{2}\Sigma^{-1})$$

$d$ is dimension of $\beta$.

\newpage

## Task 1:
Let $\textbf{B} = (\boldsymbol{\beta}_1^\top,..., \boldsymbol{\beta}_n^\top)^\top$, derive the posterior distribution of the parameters $\Theta = (\textbf{B}^\top, \boldsymbol{\beta}^\top, \sigma^2, \Sigma)$.

Note from given Bayesian model:

$$\epsilon_i(t) = Y_i(t+6) - \Big(\beta_{0,i} + \beta_{1,i}Y_i(t) + \beta_{2,i}\Delta_{i,1}(t) + \beta_{3,i}\Delta_{i,2}(t) + \beta_{4,i}\Delta_{i,3}(t)\Big) \stackrel{i.i.d}{\sim} N(0, \sigma^2)$$
$$\text{or}$$
$$Y_i(t+6) {\sim} N(\boldsymbol{X}_i(t)\boldsymbol{\beta}_i^\top, \sigma^2)$$
where $\boldsymbol{X}_i(t) = (1, Y_i(t), \Delta_{i,1}(t), \Delta_{i,2}(t), \Delta_{i,3}(t))$, and $\boldsymbol{\beta}_i = (\beta_{0,i}, \beta_{1,i}, \beta_{2,i}, \beta_{3,i}, \beta_{4,i})$. Therefore,

$$f_{Y_i(t+6)}(y_i(t+6) \mid \boldsymbol{X}_i(t), \boldsymbol{\beta}_i,  \sigma^2) = \frac{1}{\sqrt{2\pi}\sigma} \exp\Big\{-\frac{1}{2\sigma^2}\Big(y_i(t+6) - \boldsymbol{X}_i(t)\boldsymbol{\beta}_i^\top\Big)^2 \Big\}$$
for hurricane $i$ at time $t$. To show the likelihood function for hurricane $i$ across all time points, $t$, we can write the multivariate normal distribution
$$(\boldsymbol{Y}_i \mid \boldsymbol{X}_i, \boldsymbol{\beta}_i, \sigma^2) \sim \mathcal{N}(\boldsymbol{X}_i\boldsymbol{\beta}_i^\top, \sigma^2 I)$$

where $Y_i$ is an $m_i$-dimensional vector and $\boldsymbol{X}_i$ is a $m_i \times d$ matrix.

Finally, the joint likelihood function of all hurricanes can be expresses as
$$L_{Y}(\textbf{B},  \sigma^2 I) = \prod_{i=1}^n \Big\{\det(2\pi\sigma^2 I)^{-\frac{1}{2}} \exp\Big(-\frac{1}{2}(\boldsymbol{Y}_i - \boldsymbol{X}_i\boldsymbol{\beta}_i^\top)^\top (\sigma^2 I)^{-1}(\boldsymbol{Y}_i - \boldsymbol{X}_i\boldsymbol{\beta}_i^\top)\Big)\Big\}$$

where $I$ is an identical matrix with dimension consistent with $Y_i$.

We can find the posterior distribution for $\Theta$ by

$$\pi(\textbf{B}, \boldsymbol{\beta}, \sigma^2, \Sigma^{-1} \mid Y) \propto L_{Y}(\textbf{B},  \sigma^2 I) \times \pi(\textbf{B} \mid \boldsymbol{\beta}, \Sigma^{-1}) \times \pi(\boldsymbol{\beta}) \times \pi(\sigma^2) \times \pi(\Sigma^{-1}),$$

where $\pi(\textbf{B} \mid \boldsymbol{\beta},  \Sigma)$ is the joint multivariate normal density of $\beta$,

$$\pi(\textbf{B} \mid \boldsymbol{\beta},  \Sigma^{-1}) = \prod_{i=1}^n \Big\{\det(2\pi\Sigma)^{-\frac{1}{2}} \exp(-\frac{1}{2}(\boldsymbol{\beta}_i - \boldsymbol{\beta}) \Sigma^{-1}(\boldsymbol{\beta}_i - \boldsymbol{\beta})^\top) \Big\}.$$

So we have the following posterior distribution:

$$\pi(\textbf{B}, \boldsymbol{\beta}, \sigma^2, \Sigma^{-1} \mid Y) \propto \prod_{i=1}^n \Big\{(2\pi\sigma^2)^{-m_i/2} \exp\big\{-\frac{1}{2}(\boldsymbol{Y}_i - \boldsymbol{X}_i\boldsymbol{\beta}_i^\top)^\top (\sigma^2 I)^{-1}(\boldsymbol{Y}_i - \boldsymbol{X}_i\boldsymbol{\beta}_i^\top)\big\}\Big\}\\$$
$$\times \prod_{i=1}^n \Big\{\det(2\pi\Sigma)^{-\frac{1}{2}} \exp\big\{-\frac{1}{2}(\boldsymbol{\beta}_i - \boldsymbol{\beta}) \Sigma^{-1}(\boldsymbol{\beta}_i - \boldsymbol{\beta})^\top\big\}\Big\} \times \frac{1}{\sigma^2} \times |\Sigma|^{-(d+1)} \exp\big\{-\frac{1}{2}\Sigma^{-1}\big\}.$$

Rearranged,
$$\pi(\textbf{B}, \boldsymbol{\beta}, \sigma^2, \Sigma^{-1} \mid Y) \propto 
\frac{1}{\sigma^2} 
\times \prod_{i=1}^n (2\pi\sigma^2)^{-m_i/2} 
\times | \Sigma |^{-(d + 1)} \exp\big\{-\frac{1}{2}\Sigma^{-1}\big\}
\times \det(2\pi\Sigma)^{-n/2} \\$$

$$\times \prod_{i=1}^n \Big\{\exp\big\{-\frac{1}{2}(\boldsymbol{Y}_i - \boldsymbol{X}_i\boldsymbol{\beta}_i^\top)^\top (\sigma^2 I)^{-1}(\boldsymbol{Y}_i - \boldsymbol{X}_i\boldsymbol{\beta}_i^\top)\big\}\Big\}
\times \prod_{i=1}^n \Big\{\exp \big\{-\frac{1}{2}(\boldsymbol{\beta}_i - \boldsymbol{\beta})\Sigma^{-1}(\boldsymbol{\beta}_i - \boldsymbol{\beta})^\top\big\} \Big\}.$$

### Yimiao: The product is proportional, but after logarithm, the summation would not be proportional any more with other terms as fixed constants.


To find the conditional posterior distributions for Gibbs sampling, we can consider:
$$\pi(\boldsymbol{\beta} \mid \textbf{B}, \sigma^2, \Sigma, Y) = \frac{\pi(\beta, \textbf{B},\sigma^2, \Sigma \mid Y)}{\pi(\textbf{B}, \sigma^2, \Sigma \mid Y)} \propto\ ??$$

### Yimiao: Not sure about next part. The slide's second Gibbs example on Page 41 doesn't select the terms which only have sigma2, though the numerator for conditional posterior of mu contains both mu and sigma2. It seems complicated to have conditional posteriors for each parameter because we have 4 parameters instead of 2. We can try other methods later.

In the equation above, $\pi(\textbf{B}, \sigma^2, \Sigma)$ only depends on $\textbf{B}, \sigma^2, \Sigma$, so we can focus only on the part of the joint posterior that depends on all four variables $\beta,\ \textbf{B},\ \sigma^2$, and $\Sigma$.

$$\pi(\boldsymbol{\beta} \mid \textbf{B}, \sigma^2, \Sigma, Y) \propto \prod_{i=1}^n \exp\Big\{- \frac{1}{2}(\boldsymbol{\beta}_i - \boldsymbol{\beta})\Sigma^{-1}(\boldsymbol{\beta}_i - \boldsymbol{\beta})^\top\Big\}$$

I believe we want to expand and simplify to find a recognizable distribution, but I'm not sure what to do from here. Seems like I've made an error somewhere? Would it be easier to do Metropolis-Hastings?

\newpage

The log of the posterior can be written as:
$$\log{\pi(\textbf{B}, \boldsymbol{\beta}, \sigma^2, \Sigma \mid Y_i)} \propto \log f_{Y_i(t + 6)}(Y_i \mid \boldsymbol{\beta}_i, \sigma^2) + \log \pi(\Theta),$$

where

$$\pi(\Theta) \propto \prod_{i=1}^n \det(2\pi\Sigma)^{-\frac{1}{2}} \exp(-\frac{1}{2}(\boldsymbol{\beta}_i - \boldsymbol{\beta})^\top \Sigma^{-1}(\boldsymbol{\beta}_i - \boldsymbol{\beta})) \times 1 \times \frac{1}{\sigma^2} \times |\Sigma|^{-(d+1)} \exp(-\frac{1}{2}\Sigma^{-1}).$$
Therefore,
$$\log{\pi(\textbf{B}, \boldsymbol{\beta}, \sigma^2, \Sigma \mid Y_i)} \propto \sum_{i=1}^n -\frac{1}{2}\log2\pi - \log \sigma - \frac{1}{2\sigma^2}\Big(Y_i(t + 6) - \mu_i \Big)^2 +$$
$$\sum_{i=1}^n -\frac{1}{2}\log(\det(2\pi\Sigma)) - \frac{1}{2}(\boldsymbol{\beta}_i - \boldsymbol{\beta})^\top \Sigma^{-1}(\boldsymbol{\beta}_i - \boldsymbol{\beta}) - 2\log\sigma - (d+1)\log|\Sigma| - \frac{1}{2}\Sigma^{-1}.$$

Using this equation, I think we could implement a similar component-wise M-H algorithm to the Example: Hierarchical Poisson Model from lecture note 9, page 45.